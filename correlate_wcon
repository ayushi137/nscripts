#!/usr/bin/env python

"""
correlate - correlate Dragonfly images against Herschel images

Expects a particular file system set up for images to correlate: 
<parent directory>/<object name>/<raw_file_directory>/<date>/<image>/

These images can be:

1) dark subtracted and flat fielded
2) scamped and swarped
3) photometered
4) convolved
5) masked
6) cropped
7) background subtracted and correlated

Assumes a particular file system set up for images to correlate against:
<parent directory>/<object name>/<image>

These images can be:

1) masked
2) correlated

Requires the following software: sextractor, scamp, swarp astrometry.net
Requires the following packages: numpy, scipy, astropy, docopt, matplotlib, os
								 pandas, subprocess
Requires the following files:    photometry.py, resconvolve.py, maskdata.py
                                 regrid.py, backgroundplane.py, 
                                 create_photometriclights.py, scampswarp.py,
                                 rewriteherschel.py
Contains the following funcs:	 getAltAz, fexists, getsubdir, sexcall, hist2d	

Usage:
correlate [-hvlgqwpcrkb] [-d DIRECTORY] [-u DIRECTORIES] [-o OBJECTNAMES] 
		[-s DIRECTORY] [-f FILEPATHS] [-x DIRECTORY] [-a DIRECTORY] [-m MODE]

Options:
    -h, --help
    -v, --verbose
    -l, --lowmemory                 If True, use a version of regridding 
                                    code that does not require high memory 
                                    usage
    -d DIRECTORY, --indir DIR       Location of input files (parent 
                                    directory)
                                    [default: dflydata/] 
    -f FILES, --filelist FLS        Provide a list of file paths to process
                                    as a string. If empty, processes all 
                                    file in input directory. Assumes input files
                                    are in completely raw form
                                    [default: ]
    -x DIRECTORY, --cross DIR       Location of files to correlate with
                                    [default: ../herschel/]
    -a DIRECTORY, --apass DIR       Location of APASS catalogues
                                    [default: /mnt/scratch-lustre/njones/SURP2015/nscripts/APASS/]
    -m MODE, --mode MODE 			Status of input files: set to raw or calibrated
    								[default: raw]
Testing Options:
    -g, --generate                  If False, do not generate data from
                                    any of the following substeps unless 
                                    that data is missing
                                    [default: False]
    -q, --calibrate                 If False, do not dark subtract and flat 
                                    field them unless files are missing
    -w, --astro                     If False, do not do astrometry and 
                                    create object catalogue
    -p, --photometry                If False, do not perform photometry on 
                                    an image unless photometry data is 
                                    missing
    -c, --convolve                  If False, do not convolve an image 
                                    unless convolved image missing
    -r, --regrid                    If False, do not regrid an image unless
                                    regridded image is missing
    -k, --mask                      If False, do not mask an image unless
                                    masked image is missing
    -b, --backsub                   If False, do not background plane 
                                    subtract an image unless subtracted is 
                                    missing
"""
############################# IMPORT BASE PACKAGES #############################

import os
import docopt
import numpy as np
nmax = np.max
nmin = np.min
from numpy import *
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from astropy.io import fits
from astropy import units as u
from astropy import wcs
from astropy.time import Time
from astropy.coordinates import SkyCoord, EarthLocation, AltAz
from matplotlib.colors import LogNorm

########################### COMMAND LINE ARGUMENTS #############################

arguments = docopt.docopt(__doc__)

# Non-mandatory options without arguments

VERBOSE = arguments['--verbose']
LOWMEMORY = arguments['--lowmemory']

# Non-mandatory options with arguments

directory = arguments['--indir']

mode = arguments['--mode']

APASSdir = arguments['--apass']
files = arguments['--filelist']
filelist = files.split(', ')
if filelist != ['']:
	files = True
elif filelist == ['']:
	files = False
herdir = arguments['--cross']

# Testing options

GENERATE = arguments['--generate']
CALIBRATE = arguments['--calibrate']
ASTROMETRY = arguments['--astro']
PHOTOMETRY = arguments['--photometry']
CONVOLVE = arguments['--convolve']
REGRID = arguments['--regrid']
MASK = arguments['--mask']
BACKSUB = arguments['--backsub']


############################## IMPORT FUNCTIONS ################################

from cartesian import cartesian
from callastrometry import callastrometry,scrubwcsheader
from scampswarp import scampswarp
from photometrypack import *
from resconvolve import resconvolve
from maskdata import maskdata
from regrid import reshape
from backgroundplane import subBGplane,fillplane,plane

if LOWMEMORY:
	from regrid import regrid_lowmemory as regrid
elif not LOWMEMORY:
	from regrid import regrid

################################ CONFIG FILE ####################################

from correlate_config import *

rawdir = config_data['raws']
caldir = config_data['cals']
subdir = config_data['dsff']
objects = config_data['objects']

################################ CONSTANTS ####################################

# Telescope location
telescope = EarthLocation(lat=scope_lat[config_data['scope']],
						  lon=scope_long[config_data['scope']],
						  height = scope_alt[config_data['scope']])

# Conversion factor to transform sigma of scipy.signal.gaussian to FWHM
s2f = 2*np.sqrt(2*log(2))


#################################### FUNCTIONS #################################

def getAltAz(arr,header,time,location):
	"""
	Converts an array with WCS to altitude and azimuth coordinates
	arr:	 	array of values
	header:	 	header containing appropriate WCS solution
	time:	 	time of observations
	location:	location of observations

	Returns a list of altitude, azimuth, xpixel and ypixel coordinates
	"""
	soln = wcs.WCS(header)
	coords = cartesian([arange(arr.shape[1]),arange(arr.shape[0])])
	world = soln.wcs_pix2world(coords,0)
	radec = SkyCoord(ra=world[:,0],dec=world[:,1],frame='icrs',unit='deg')
	altaz = radec.transform_to(AltAz(obstime=time,location=telescope))
	return altaz.alt.deg,altaz.az.deg,coords[:,0],coords[:,1]

def fexists(fname):
	"""
	fname: 	file to check existence of

	Returns True if file exists, otherwise False
	"""
	if os.path.isfile(fname) == True:
		return True
	elif os.path.isfile(fname) != True:
		return False

def getsubdir(directory):
	"""
	Gets all immediate subdirectories of directory

	directory:	path to directory

	Returns a list of subdirectories
	"""
	subdir=[name for name in os.listdir(directory)
			if os.path.isdir(os.path.join(directory, name))]
	subdir=['/'+name+'/' for name in subdir if '.' not in name]
	return subdir


def sexcall(f,ddi,odi,cdi,bdi):
	"""
	Run source extractor on f, producing a catalogue, and object and background maps

	f:		file name to run source extractor on
	ddi:	directory path to f
	odi:	directory to save object map in
	cdi:	directory to save catalogue in
	bdi:	directory to save background map in

	Returns nothing explicitly, but runs source extractor on the file
	"""
	# Split to make file name for catalogue, 
	# object map and background map filenames
	fname = f.split('.fits')[0]
	# Construct source extractor call
	objsexcall = 'sex -CATALOG_TYPE ASCII_HEAD -PARAMETERS_NAME photo.param -CATALOG_NAME '+cdi+fname+'.cat'+' -CHECKIMAGE_TYPE OBJECTS -CHECKIMAGE_NAME '+odi+fname+'_objects.fits '+ddi+f
	baksexcall = 'sex -CATALOG_TYPE ASCII_HEAD -PARAMETERS_NAME photo.param -CATALOG_NAME '+cdi+fname+'.cat'+' -CHECKIMAGE_TYPE BACKGROUND -CHECKIMAGE_NAME '+bdi+fname+'_background.fits '+ddi+f
	os.system(objsexcall)
	os.system(baksexcall)

def hist2d(x,y,nbins = 50 ,maskval = 0,saveloc = '',labels=[],slope = 1,sloperr = 0):
	"""
	Creates a 2D histogram from data given by numpy's histogram

	x,y:		two 2D arrays to correlate
	nbins:		number of bins
	maskval:	value that indicates masked areas
				(kwarg, default = 0)
	saveloc:	place to save histogram plot - if unspecified, do not
				save plot (kwarg, default = '')
	labels:		labels for histogram plot, with the following format
				[title,xlabel,ylabel,zlabel] - if unspecified, do 
				not label plot (kwarg, default = [])
	slope:		slope of correlation fit line (kwarg, default = 1)
	slopeerr:	uncertainties in slope of fit line (kwarg, default = 0)

	Returns the edges of the histogram bins and the 2D histogram

	"""
	# Remove NANs and masked values
	good = where((isnan(x) == False) & (isnan(y) == False) & (x != maskval) & (y != maskval))
	x = x[good]
	y = y[good]

	# Create histogram
	H,xedges,yedges = histogram2d(x,y,bins=nbins)
	# Reorient appropriately
	H = rot90(H)
	H = flipud(H)
	# Mask zero value bins
	Hmasked = ma.masked_where(H==0,H)
	# Find average values in y:
	yavgs = []
	ystds = []
	xposs = []
	for j in range(len(xedges)-1):
		toavg = where((x > xedges[j]) & (x < xedges[j+1]))
		xpos = np.mean(x[toavg])
		yavg = np.median(y[toavg])
		ystd = np.std(y[toavg])/len(y[toavg])
		xposs.append(xpos)
		yavgs.append(yavg)
		ystds.append(ystd)
	# Begin creating figure
	plt.figure(figsize=(12,10))
	# Make histogram pixels with logscale
	plt.pcolormesh(xedges,yedges,Hmasked,
	               norm = LogNorm(vmin = Hmasked.min(),
	                              vmax = Hmasked.max()),
		       	   cmap = plt.get_cmap('Spectral_r'))
	# Create fit line x-array
	uplim = nmax(x)+5
	dolim = nmin(x)-5
	x_range = arange(dolim,uplim)
	# Plot fit line
	plt.plot(x_range,slope*x_range,color = 'royalblue',linewidth = 3,label = 'Slope = {0}, Uncertainty = {1}'.format(slope,sloperr))
	# Plot average points
	plt.errorbar(xposs,yavgs,yerr = ystds,fmt = 'D',color='k',markersize = 5)
	# Set plot limits
	plt.xlim(dolim+5,uplim-5)
	plt.ylim(nmin(y),nmax(y))
	# Add colourbar
	cbar = plt.colorbar()
	# Add labels
	if labels != []:
	    title,xlabel,ylabel,zlabel = labels
	    plt.xlabel(xlabel)
	    plt.ylabel(ylabel)
	    plt.title(title)
	    cbar.ax.set_ylabel(zlabel)
	    plt.legend(loc = 'best',fontsize = 15)
	# Save plot
	if saveloc != '':
		plt.savefig(saveloc)
	plt.close()
	# Return histogram
	return xedges,yedges,Hmasked


######################### FIND FILES AND PREP FOR OUTPUT ######################

# If file list given
if files:
	if VERBOSE:
		print 'Finding objects and dates for each file in the list.'
	objectdates = {}
	datenames = {}
	objectherfiles = {}
	# Find directory where first file is located
	breakdown = filelist[0].split('/')
	breakdown = [i for i in breakdown if i != '']
	# Extract file name, date, raw directory name and object
	fname = breakdown.pop(-1)
	date = breakdown.pop(-1)
	rawdir = '/'+breakdown.pop(-1)+'/'
	objs = breakdown.pop(-1)
	# Find parent directory
	directory = '/'+'/'.join(breakdown)+'/'
	for f in filelist:
		# Repeat the process of finding parent directory and file info
		breakdown = f.split('/')
		breakdown = [i for i in breakdown if i != '']
		fname = breakdown.pop(-1)
		date = breakdown.pop(-1)
		# Confirm that the parent directory and raw file directory
		# are the same as for the first file
		newrawdir = '/'+breakdown.pop(-1)+'/'
		try:
			assert newrawdir == rawdir
		except AssertionError:
			filelist.remove(f)
			print 'Please choose files within '+rawdir
			continue
		cloud = breakdown.pop(-1)
		newdirectory = '/'+'/'.join(breakdown)+'/'
		try:
			assert newdirectory == directory
		except AssertionError:
			filelist.remove(f)
			print 'Please choose files within '+directory
			continue
		# Update the dictionaries with directory data for this filename
		try:
			datenames[date].append(fname)
		except KeyError:
			datenames[date] = [fname]
		try:
			objectdates[cloud].append(date)
		except KeyError:
			objectdates[cloud] = [date]
		# Find files to correlate against
		hdirec = herdir+'/'+cloud
		if config_data['rwcorrfiles']:
			os.system('python rewriteherschel.py -d '+hdirec)
		herfiles = os.listdir(hdirec)
		# Attach appropriate correlate images for the cloud
		if config_data['rwcorrfiles']:
			objectherfiles[cloud] = [hdirec+'/'+i for i in herfiles 
					 				 if 'reindex' in i]
		if not config_data['rwcorrfiles']:
			objectherfiles[cloud] = [hdirec+'/'+i for i in herfiles]

# If files are not specified
if not files:
	if VERBOSE:
		print 'Finding date and cloud information for this directory: '+directory
	# Dictionaries to hold correlate file and date information
	objectdates = {}
	datenames = {}
	objectherfiles = {}
	for cloud in objects:
		direc = directory+'/'+cloud+rawdir
		subdirs = getsubdir(direc)
		# Only return date subdirectories 
		# Since Dragonfly is new, all date stamps contain 2015
		subdirs = [i for i in subdirs if '20' in i]
		# List all observing dates for this cloud in dictionary
		objectdates[cloud] = subdirs
		hdirec = herdir+'/'+cloud
		if config_data['rwcorrfiles']:
			os.system('python rewriteherschel.py -d '+hdirec)
		herfiles = os.listdir(hdirec)
		# Attach appropriate correlate images for the cloud
		if config_data['rwcorrfiles']:
			objectherfiles[cloud] = [hdirec+'/'+i for i in herfiles 
					 				 if 'reindex' in i]
		if not config_data['rwcorrfiles']:
			objectherfiles[cloud] = [hdirec+'/'+i for i in herfiles]
		# Find individual file names
		for date in subdirs:
			fnames = os.listdir(direc+'/'+date)
			datenames[date] = fnames

objects = objectdates.keys()

if VERBOSE:
	print 'If needed, create top level output directories.'
# If any of the output directories are missing, create them now
dirlist = [damdir,flmdir,dsmdir,objdir,bakdir,catdir,subdir,phodir,
	       regdir,cordir,magdir,bsudir]
for d in dirlist:
    for cloud in objects:
        if os.path.isdir(directory+cloud+d) == False:
            os.system('mkdir '+directory+cloud+d)

################################ BEGIN PROCESSING #####################################

for cloud in objects:
	if VERBOSE:
		print 'OBJECT '+cloud
	dates = objectdates[cloud]
	herfiles = objectherfiles[cloud]
	for date in dates:
		if VERBOSE:
			print 'DATE '+date

################################ CALIBRATE #####################################
		fs = datenames[date]
	# if no files found for this date skip to next
		if fs == []:
			if VERBOSE:
				print 'No files here, continuing'
				continue
	# Do dark subtraction and flat fielding on files as a group
		if GENERATE or CALIBRATE:
			if VERBOSE:
				print 'Force generate calibration files'
			if files:
				calcom = ('python calibratedata -gv -f '+
					  (', ').join(filelist))
			if not files:
				calcom = ('python calibratedata -gv  -o '+cloud+
					  ' -t '+date)
			os.system(calcom)
		if not GENERATE and not CALIBRATE:
			if VERBOSE:
				print 'Check for calibration files'
			if files:
				calcom = ('python calibratedata -v -f '+
					  (', ').join(filelist))
			if not files:
				calcom = ('python calibratedata -v -o '+cloud+
					  ' -t '+date)
			os.system(calcom)
	if VERBOSE:
		print 'Check for output directories'

    # Directory containing raw image files
	di = directory+cloud+rawdir+date+'/'
    # Directory containing dark subtracted and flat fielded files
	ddi = directory+cloud+subdir+date+'/'
    # Directory containing source extractor object maps
	odi = directory+cloud+objdir+date+'/'
    # Directory containing source extractor catalogues
	cdi = directory+cloud+catdir+date+'/'
    # Directory containing source extractor background maps
	bdi = directory+cloud+bakdir+date+'/'
    # Directory containing photometered images
	pdi = directory+cloud+phodir+date+'/'
    # Directory containing regridded images
	rdi = directory+cloud+regdir+date+'/'
    # Directory containing masked images
	mdi = directory+cloud+magdir+date+'/'
    # Directory containing background subtracted images
	gdi = directory+cloud+bsudir+date+'/'
    # Directory containing correlation plots
	sdi = directory+cloud+cordir+date+'/'

	if VERBOSE:
		print 'If needed, generate lower level output directories'
    # Create output directories if any are missing
	for d in dirlist:
		if os.path.isdir(directory+cloud+d+date) == False:
			os.system('mkdir '+directory+cloud+d+date+'/')

################################ CYCLE FILES ###################################
    
	for f in fs:
		try:
			if VERBOSE:
				print 'FILE '+di+f
				
			f = f.split('.fits')[0]+'_ds_ff.fits'
	  
	        # Confirm calibrated file exists
			assert os.path.isfile(ddi+f) == True
			spl = f.split('.fits')[0]

################################ ASTROMETRY ####################################
			
			if GENERATE==True or ASTROMETRY==True:
				if VERBOSE:
					print 'Do astrometry for '+f
				scrubwcsheader(ddi+f)
				callastrometry(ddi+f,generate=True)
			else:
				if VERBOSE:
					print 'Check for astrometry for '+f
				callastrometry(ddi+f)
			if GENERATE==True or ASTROMETRY==True or fexists(ddi+spl+'_ss.fits') == False:
				if VERBOSE:
					print 'Scamp and swarp '+f
				scampswarp(ddi+f)
			if VERBOSE:
				print 'Update '+f+' header with SWARP WCS'
			
		
				
			oldhead = fits.getheader(ddi+f)
			f = spl+'_ss.fits'
			fspl = f.split('.fits')[0]
			ssdata,newhead = fits.getdata(ddi+f,header=True)
			uphead = oldhead.copy()
			uphead.update(newhead)
			fits.writeto(ddi+f,ssdata,uphead,clobber=True)
			if GENERATE==True or ASTROMETRY==True or fexists(cdi+fspl+'.cat') == False or fexists(bdi+fspl+'_background.fits') == False:
				sexcall(f,ddi,odi,cdi,bdi)

################################ IMAGE PROPERTIES ##############################
	        # Read in ds-ff-ss data from file
			if VERBOSE:
				print 'Read '+f
			dflyimage = fits.open(ddi+f)
			dflydata = dflyimage[0].data
			if VERBOSE:
				print 'Remove NAN data from '+f
			dflydata[where(isnan(dflydata)==True)] = 0
			dflyheader = dflyimage[0].header
			dflyimage.close()
			# Load WCS solution
			soln = wcs.WCS(dflyheader)
	    	# Load catalogue data to find FWHM information
			catdata = loadtxt(cdi+fspl+'.cat')
	        # Find pixel scale from astrometry info
			pscalx = dflyheader['PSCALX']
			pscaly = dflyheader['PSCALY']
			pixscale = (pscalx+pscaly)/2.
	        # Select for unflagged entries
			cheader = catheader(cdi+fspl+'.cat')
			catdata = catdata[where(catdata[:,cheader['FLAGS']] == 0)]
			catdata = catdata[where(catdata[:,cheader['CLASS_STAR']]<1e-15)]
	        # Find the average FWHM and convert to arcseconds
			pfwhm = mean(catdata[:,cheader['FWHM_IMAGE']])
			dflybeam = pfwhm*pixscale
			if isnan(dflybeam)==True: 
				if VERBOSE:
					print 'No Dragonfly resolution found'
				continue
	        # Add FWHM to header
			dflyheader['FWHM'] = (dflybeam, 'arcseconds')
			fits.writeto(ddi+f,dflydata,dflyheader,clobber=True)
	        # If polarization data, skip
			if dflyheader['FILTNAM'] == 'Pol':
				print 'Skipping polarization data in '+f
				continue
			if VERBOSE:
				print 'Header up to date in '+f  

	################################ PHOTOMETRY ###################################      
	        # Choose photometered file name
	        # Choose output location for photometry related plots
			outplots = mdi+fspl
	        # Run photometry
			pname = fspl+'_photo.fits'
			if (os.path.isfile(pdi+pname) != True or GENERATE == True or 
			    PHOTOMETRY == True):
				if VERBOSE:
					print 'Run photometry for '+f
				# Use Jielai's photometery
				os.system('python create_photometriclights.py -pklnv -u {0} -o {1} -i {1} -r {2} -s {3}'.format(ddi+f,ddi,APASSdir,'/opt/sextractor/2.8.6/bin/sex'))
				try:
					if VERBOSE:
						print 'Crop zeroes out of '+f
					photodat,H = fits.getdata(ddi+f.split('.fits')[0]+'_pcp_pcr.fits',header = True)
					photodat = reshape(photodat,photodat,0,limval=0)
				except IOError:
					if VERBOSE:
						print 'Missing photometry for '+f+', skipping'
					continue
				if VERBOSE:
					print 'Convert '+f+' to kJy/sr'
				# Find zero point magnitude
				zp = H['ZP3']
				# Find conversion factor
				kJperADU = float(tokjypersr(1,pixscale,zp))
				H['kJpADU'] = (kJperADU,'kJy/sr per ADU/pixel')
				H['M0'] = zp
				# Write converted data to file
				fits.writeto(pdi+pname,photodat*kJperADU,H,clobber=True)
				# Find WCS (again why is this here?)
				callastrometry(pdi+pname,generate=True)
				dflyheader = H
			elif (os.path.isfile(pdi+pname) == True and GENERATE == False and 
			      PHOTOMETRY == False):
				if VERBOSE:
					print 'Load photometry data for '+f
				pdata,dflyheader = fits.getdata(pdi+pname,header=True)
				zp = dflyheader['M0']
	        # If photometry failed, quit
			if zp == 'N/A':
				if VERBOSE:
					print 'Photometry failed for '+f+', skipping'
				continue
	        # Convert units in object and background map
			try:
				convert = dflyheader['kJpADU']
			except KeyError:
				if VERBOSE:
					print 'Could not find conversion factor for '+f+', skipping'
				continue
			pspl = pname.split('.fits')[0]
			if GENERATE==True or fexists(odi+pspl+'_objects.fits')==False or PHOTOMETRY==True:
				if VERBOSE:
					print 'Creating photometered object and background maps for '+f
				sexcall(pname,pdi,odi,cdi,bdi)
	        
	################################ CYCLE CORRELATION FILES #########################
			
			if VERBOSE:
				print 'Cycle through files to correlate '+f+' against'
			for hername in herfiles:
				skey = [i for i in spirekeys if i in hername][0]
				herbeam = SPIRE[skey]

	################################ CONVOLUTION #####################################
	            # Create output file names
				cname = pspl+'_convto'+str(herbeam)+'.fits'
				ocname = pspl+'_convto'+str(herbeam)+'_objects.fits'
	            # Do convolution on sky image
				if (os.path.isfile(pdi+cname) == True and 
				    GENERATE == False and CONVOLVE == False):
					if VERBOSE:
						print 'Getting convolved data for '+cname
					cdata,dflyheader = fits.getdata(pdi+cname,header=True)
				elif os.path.isfile(pdi+cname) != True or GENERATE == True or CONVOLVE == True:
					if VERBOSE:
						print 'Creating convolved data for '+pname
					cdata,dflyheader = resconvolve(pdi+pname,dflybeam,herbeam,
								       outfile = pdi+cname,
								       header = dflyheader)
	            # Do convolution on object map
				if os.path.isfile(odi+ocname) == True and GENERATE == False and CONVOLVE == False:
					if VERBOSE:
						print 'Getting convolved data for '+cname+' objects'
					ocdata,oheader = fits.getdata(odi+ocname,header=True)
				elif os.path.isfile(odi+ocname) != True or GENERATE == True or CONVOLVE == True:
					if VERBOSE:
						print 'Creating convolved data for '+cname+' objects'
					ocdata,oheader = resconvolve(odi+pspl+'_objects.fits',
	                						     dflybeam,herbeam,
								     outfile = odi+ocname,
								     header = dflyheader)
				# if dlyheader = 0 it means something went wrong in convolution
				if dflyheader == 0:
					if VERBOSE:
						print 'Convolution failed, skipping file '+f
					continue

	################################ MASK #####################################
				if VERBOSE:
					print 'Setting cutoff'
				# find information for setting cutoff value (kJy/sr) from config file
				# Either create cutoff from map values
				if config_data['cutoff'] == 0:
					if config_data['cutoff_type'] == 'median':
						cutoff = config_data['cutoff_mult']*median(ocdata)
					if config_data['cutoff_type'] == 'mean':
						cutoff = config_data['cutoff_mult']*mean(ocdata)
				# or set hard cutoff for all maps
				elif config_data['cutoff'] != 0:
					cutoff = config_data['cutoff'] 
				if VERBOSE:
					print 'Masking'
				# Create map to which pixels should be masked
				mapcut = fits.getdata(odi+ocname)
				mapcut[where(mapcut > cutoff)] = 0
	            # Create mask name
				mspl = cname.split('.fits')[0]
				mname = mspl+'_mask{0}kJysr.fits'.format(cutoff)
				fits.writeto(odi+mspl+'_mask{0}kJysr_objects.fits'.format(cutoff),mapcut,dflyheader,clobber=True)

	            # Mask data
				if os.path.isfile(pdi+mname) == True and GENERATE == False and MASK == False:
					mdata,dflyheader = fits.getdata(pdi+mname,header=True)
					target = fits.getdata(hername)
				if os.path.isfile(pdi+mname) != True or GENERATE == True or MASK == True or dflyheader['MASKCUT'] - cutoff > 1e-15:
					cdata,target = regrid(pdi+cname,hername)
					ocdata,target = regrid(odi+ocname,hername)
					mdata,dflyheader = maskdata(cdata,ocdata,cutoff,
								    outfile = pdi+mname,
								    header = dflyheader)
				p0 = [2,1,1,1]
	################################ CROP #####################################  
				if VERBOSE:
					print 'Cropping masked image back to a rectangle'
				mspl = mname.split('.fits')[0]
				ress = np.sqrt((dflybeam/s2f)**2+(herbeam/s2f)**2)
				r = reshape(mdata,mdata,2*ress)
				t = reshape(target,mdata,2*ress)
				rname = mspl+'_crop.fits'
				fits.writeto(rdi+rname,r,dflyheader,clobber=True)

	################################ BACK-SUB #####################################
				if VERBOSE:
					print 'Performing background plane fit and creating correlation'
				rspl = rname.split('.fits')[0]
				bname = rspl+'_backsub.fits'
				p0 = [2,1,1,1]
				newr,bg,ps,errs = subBGplane(r,t,p0)
				hheader = fits.getheader(hername)
				time = Time(dflyheader['DATE'])
				planefill = zeros((90,360))
				alt,az,xpix,ypix = getAltAz(bg,hheader,time,telescope)
				alt = alt[0::100]
				az = az[0::100]
				xpix = xpix[0::100]
				ypix = ypix[0::100]
				temp = []
				for i in range(len(xpix)):
					temp.append(bg[ypix[i]][xpix[i]])
				plt.figure(figsize = (12,10))
				plt.tripcolor(az,alt,temp,cmap = plt.cm.gray)
				plt.colorbar()
				plt.xlabel('Azimuth [deg]')
				plt.ylabel('Altitude [deg]')
				plt.savefig(bdi+mspl+'_bgplane_azalt.png')
				plt.close()
				if isinstance(newr,float) != True:
					dflyheader['BACKSUB'] = 'TRUE'
					dflyheader['BACKDIF'] = nmax(bg)-nmin(bg)
					dflyheader['SLOPE'] = ps[0]
					dflyheader['SLOPE_ERR'] = errs[0,0]
					dflyheader['XDEP'] = ps[1]
					dflyheader['XDEP_ERR'] = errs[1,1]
					dflyheader['YDEP'] = ps[2]
					dflyheader['YDEP_ERR'] = errs[2,2]
					dflyheader['PCONST'] = ps[3]
					dflyheader['PCONST_ERR'] = errs[3,3]
					if dflyheader['FILTNAM'] == 'SloanR':
						dflyheader['GSLOPE'] = ps[-1]*4.811e14
					if dflyheader['FILTNAM'] == 'SloanG':
						dflyheader['GSLOPE'] = ps[-1]*6.285e14
					fits.writeto(gdi+bname,newr,dflyheader,clobber=True)
					fits.writeto(bdi+mspl+'_bgplane.fits',bg,dflyheader,clobber=True)
					bspl = bname.split('.fits')[0]
					saveloc = sdi+bspl+'_'+skey+'.png'
					title = 'Correlation between Dragonfly and Herschel'
					xlabel = 'Herschel [MJy/sr]'
					ylabel = 'Dragonfly [kJy/sr]'
					zlabel = 'Pixels'
					labels = [title,xlabel,ylabel,zlabel]
					pos = where(r > 0)
					H = hist2d(t[pos],newr[pos],50,saveloc=saveloc,labels = labels,slope = ps[0],sloperr = errs[0,0])
				elif isinstance(newr,float) == True:
					print 'Failed background subtraction'
					continue
				print 'Done ', mname,'\n\n\n\n\n\n'
		except AssertionError as e:
			if VERBOSE:
				print e
				print 'Calibrated file missing for ',f
			continue

